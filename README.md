## Tutorial Title
Applied Deep Learning for NLP Applications

## Abstract
Natural language processing (NLP) has become an important field with interest from many important sectors that leverage modern deep learning methods for approaching several NLP problems and tasks such as text summarization, question answering, and sentiment classification, to name a few. In this tutorial, we will introduce several of the fundamental NLP techniques and more modern approaches (BERT, GTP-2, etc.) and show how they can be applied to approach many real-world NLP problems. We will focus on how to build an NLP pipeline using several open-source tools such as spaCy and TensorFlow. Then we will learn how to use the model to search over documents based on semantic relationships. We will use open-source technologies such as BERT and Elasticsearch for this segment to build a simple proof of concept. In essence, the learner will take away the important theoretical pieces needed to build practical NLP pipelines to address a wider variety of problems. 

## Audience
The target audience for this tutorial are ideally participants with some exposure to the Python programming language and have used natural language processing language tools such as spaCy or NLTK. Knowledge of machine learning tools and concepts is also a benefit as we will be using them in this tutorial. Beginners are also welcome but still require at least some theoretical understanding of NLP and machine learning concepts.

## Tentative Outline (for 3.5 hours)

### Module 1 - Introduction to NLP Fundamentals (30 minutes)
In this module we will brielfy introduce the fundamental NLP and deep learning concepts that are necessary to begin building more sophisticated NLP pipelines that will eventually lead to building models that can be used to approach several natural langauge problems. For instance, we will cover how to properly tokenize text, create vocabularies, train language models, etc.

*Exercise (30 minutes):* Participants will be asked to train their own language model using state-of-the art methods and tools. This includes practising tokenization and lagnuage processing techniques. 

Coffee Break (15 mins)

### Module 2 - Creating, Training and Testing an NLP model (30 minutes)
In this module we will build upon the previous module and begin to apply langauge models for addressing NLP tasks such as text classification, text generation, text suammarization, etc. The participants will essentially learn how to apply NLP transer learning approaches to properly define, train, test, and evaluate the NLP model using TensorFlow and Keras. 

*Exercise (30 minutes):* Participants will be asked to create their own model based on vanilla deep learning methods such as CNN and RNNs. 

Coffee Break (15 mins)

### Module 3 - Building Real-World NLP Applications (30 minutes)
In this module we are going to focus on putting all the learning that was acquired in the previous modules and build and test a proof of concept NLP application using purely open source technologies such as BERT and Elasticsearch. The application will be centred around a search applicaiton which can be used to further build powerful tools such as recommendation systems and ranking documents.

*Exercise (30 minutes):* Participants will be asked to leverage the techniques/knowledge learned and the tools used in the previous modules to brainstorm ideas and quickly create prototype for real-world projects. This will potentially be a group exercise. 
